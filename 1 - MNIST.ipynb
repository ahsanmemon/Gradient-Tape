{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xmf_JRJa_N8C"
   },
   "source": [
    "<table align=\"center\">\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"http://introtodeeplearning.com\">\n",
    "        <img src=\"http://introtodeeplearning.com/images/colab/mit.png\" style=\"padding-bottom:5px;\" />\n",
    "      Visit MIT Deep Learning</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/aamini/introtodeeplearning/blob/master/lab2/Part1_MNIST.ipynb\">\n",
    "        <img src=\"http://introtodeeplearning.com/images/colab/colab.png?v2.0\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/aamini/introtodeeplearning/blob/master/lab2/Part1_MNIST.ipynb\">\n",
    "        <img src=\"http://introtodeeplearning.com/images/colab/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />View Source on GitHub</a></td>\n",
    "</table>\n",
    "\n",
    "# Copyright Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKA_J7bdP33T"
   },
   "outputs": [],
   "source": [
    "# Copyright 2020 MIT 6.S191 Introduction to Deep Learning. All Rights Reserved.\n",
    "# \n",
    "# Licensed under the MIT License. You may not use this file except in compliance\n",
    "# with the License. Use and/or modification of this code outside of 6.S191 must\n",
    "# reference:\n",
    "#\n",
    "# Â© MIT 6.S191: Introduction to Deep Learning\n",
    "# http://introtodeeplearning.com\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RsGqx_ai_N8F"
   },
   "outputs": [],
   "source": [
    "# Import Tensorflow 2.0\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf \n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "try: \n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
    "except: \n",
    "  # Invalid device or cannot modify virtual devices once initialized. \n",
    "  pass \n",
    "\n",
    "# !pip install mitdeeplearning\n",
    "import mitdeeplearning as mdl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check that we are using a GPU, if not switch runtimes\n",
    "#   using Runtime > Change Runtime Type > GPU\n",
    "# assert len(tf.config.list_physical_devices('GPU')) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HKjrdUtX_N8J"
   },
   "source": [
    "## 1.1 MNIST dataset \n",
    "\n",
    "Let's download and load the dataset and display a few random samples from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2dQsHI3_N8K"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = (np.expand_dims(train_images, axis=-1)/255.).astype(np.float32)\n",
    "train_labels = (train_labels).astype(np.int64)\n",
    "test_images = (np.expand_dims(test_images, axis=-1)/255.).astype(np.float32)\n",
    "test_labels = (test_labels).astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ZtUqOqePsRD"
   },
   "source": [
    "Our training set is made up of 28x28 grayscale images of handwritten digits. \n",
    "\n",
    "Let's visualize what some of these images and their corresponding training labels look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vec9qcJs-9W5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  240       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            multiple                  7812      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  115328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 124,670\n",
      "Trainable params: 124,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_cnn_model():\n",
    "    cnn_model = tf.keras.Sequential([\n",
    "\n",
    "        # TODO: Define the first convolutional layer\n",
    "        tf.keras.layers.Conv2D(24, (3,3), activation=tf.nn.relu), \n",
    "\n",
    "        # TODO: Define the first max pooling layer\n",
    "        tf.keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "        # TODO: Define the second convolutional layer\n",
    "        tf.keras.layers.Conv2D(36, (3,3), activation=tf.nn.relu),\n",
    "\n",
    "        # TODO: Define the second max pooling layer\n",
    "        tf.keras.layers.MaxPool2D((2,2)),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "\n",
    "        # TODO: Define the last Dense layer to output the classification \n",
    "        # probabilities. Pay attention to the activation needed a probability\n",
    "        # output\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "#         '''TODO: Dense layer to output classification probabilities'''\n",
    "    ])\n",
    "    \n",
    "    return cnn_model\n",
    "  \n",
    "cnn_model = build_cnn_model()\n",
    "# Initialize the model by passing some data through\n",
    "cnn_model.predict(train_images[[0]])\n",
    "# Print the summary of the layers in the model.\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-2glsRiMdqa"
   },
   "source": [
    "## 1.4 Training the model 2.0\n",
    "\n",
    "Earlier in the lab, we used the [`fit`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#fit) function call to train the model. This function is quite high-level and intuitive, which is really useful for simpler models. As you may be able to tell, this function abstracts away many details in the training call, and we have less control over training model, which could be useful in other contexts. \n",
    "\n",
    "As an alternative to this, we can use the [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape) class to record differentiation operations during training, and then call the [`tf.GradientTape.gradient`](https://www.tensorflow.org/api_docs/python/tf/GradientTape#gradient) function to actually compute the gradients. You may recall seeing this in Lab 1 Part 1, but let's take another look at this here.\n",
    "\n",
    "We'll use this framework to train our `cnn_model` using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wq34id-iN1Ml",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, step: 100, training_acc: 0.8125, val_acc: 0.82\n",
      "\t'1' out of '8' grads are zero\n",
      "epoch: 1, step: 200, training_acc: 0.84375, val_acc: 0.95\n",
      "\tepoch: 1, step: 300, training_acc: 0.953125, val_acc: 0.96\n",
      "\tepoch: 1, step: 400, training_acc: 0.9375, val_acc: 0.97\n",
      "\tepoch: 1, step: 500, training_acc: 0.984375, val_acc: 0.98\n",
      "\tepoch: 1, step: 600, training_acc: 1.0, val_acc: 0.98\n",
      "\tepoch: 1, step: 700, training_acc: 1.0, val_acc: 1.0\n",
      "\tepoch: 1, step: 800, training_acc: 1.0, val_acc: 0.98\n",
      "\tepoch: 1, step: 900, training_acc: 0.953125, val_acc: 1.0\n",
      "\tepoch: 2, step: 1000, training_acc: 0.984375, val_acc: 1.0\n",
      "\tepoch: 2, step: 1100, training_acc: 0.96875, val_acc: 0.97\n",
      "\tepoch: 2, step: 1200, training_acc: 0.96875, val_acc: 1.0\n",
      "\tepoch: 2, step: 1300, training_acc: 0.96875, val_acc: 1.0\n",
      "\t'1' out of '8' grads are zero\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6c43ecc59092>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mcnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;31m#         optimizer.apply_gradients(zip(grads, cnn_model.trainable_weights))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mr_binary_op_wrapper\u001b[1;34m(y, x)\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m   \u001b[1;31m# Propagate func.__doc__ to the wrappers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1204\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow2\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6683\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   6684\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Mul\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6685\u001b[1;33m         name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[0;32m   6686\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6687\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Rebuild the CNN model\n",
    "from IPython.display import clear_output\n",
    "cnn_model = build_cnn_model()\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "loss_history = mdl.util.LossHistory(smoothing_factor=0.95) # to record the evolution of the loss\n",
    "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss', scale='semilogy')\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3) # define our optimizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# @tf.function\n",
    "def grad_stats(grads):\n",
    "    grad_sum = np.array([(grad.numpy()).sum() for grad in grads])\n",
    "    zero_grad_count = (grad_sum==0).sum()\n",
    "    if zero_grad_count>0:\n",
    "        print(f\"'{zero_grad_count}' out of '{grad_sum.shape[0]}' grads are zero\")\n",
    "\n",
    "import time\n",
    "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
    "step_counter = 1\n",
    "epoch_time = 0\n",
    "for e in range(epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    for i, idx in enumerate(range(0, train_images.shape[0], batch_size)):\n",
    "        step_counter+=1\n",
    "        (images, labels) = train_images[idx:idx+batch_size], train_labels[idx:idx+batch_size]\n",
    "        images = tf.convert_to_tensor(images)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = cnn_model(images)\n",
    "            loss_value = tf.keras.backend.sparse_categorical_crossentropy(labels, logits)\n",
    "\n",
    "        grads = tape.gradient(loss_value, cnn_model.trainable_weights)\n",
    "        \n",
    "        for i in range(len(cnn_model.trainable_weights)): \n",
    "            cnn_model.trainable_weights[i].assign(cnn_model.trainable_weights[i] - (lr*grads[i]))        \n",
    "#         optimizer.apply_gradients(zip(grads, cnn_model.trainable_weights))\n",
    "\n",
    "        prediction_probs = logits\n",
    "        predictions = np.argmax(logits, axis=1)\n",
    "        acc_score = accuracy_score(labels, predictions)\n",
    "\n",
    "        val_probs = cnn_model(test_images[0:100])\n",
    "        val_predictions = np.argmax(val_probs, axis=1)\n",
    "        val_accuracy = accuracy_score(test_labels[0:100], val_predictions)\n",
    "#         loss_numpy = np.mean(loss_value.numpy())\n",
    "        if step_counter%100==0:\n",
    "            print(\"epoch: {}, step: {}, training_acc: {}, val_acc: {}\".format(e+1, step_counter, acc_score, val_accuracy))\n",
    "            print(\"\\t\", end=\"\")\n",
    "            grad_stats(grads)\n",
    "#         break\n",
    "\n",
    "    epoch_time = time.time()-epoch_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions(test_images, cnn_model, n_images = 20):\n",
    "    start_point = np.random.randint(test_images.shape[0]-n_images)\n",
    "    my_test_images = test_images[start_point:start_point+n_images]\n",
    "    predictions = np.argmax(cnn_model(my_test_images), axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(15,3))\n",
    "    for i in range(my_test_images.shape[0]):\n",
    "        plt.subplot(1, n_images, i+1)\n",
    "        plt.title(predictions[i])\n",
    "        plt.imshow(my_test_images[i].reshape(28,28))\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "display_predictions(test_images, cnn_model, n_images=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Xmf_JRJa_N8C"
   ],
   "name": "Part1_MNIST.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/aamini/introtodeeplearning/blob/master/lab2/Part1_mnist_solution.ipynb",
     "timestamp": 1578013521511
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
